<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Programming | Aritra Biswas</title>
    <link>http://localhost:4321/category/programming/</link>
      <atom:link href="http://localhost:4321/category/programming/index.xml" rel="self" type="application/rss+xml" />
    <description>Programming</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 09 Mar 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:4321/media/icon_hu966111359855668688.png</url>
      <title>Programming</title>
      <link>http://localhost:4321/category/programming/</link>
    </image>
    
    <item>
      <title>On LLM reproducibility</title>
      <link>http://localhost:4321/post/on-llm-reproducibility/</link>
      <pubDate>Sun, 09 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/on-llm-reproducibility/</guid>
      <description>&lt;p&gt;One of the major issue with LLM output is its consistency and reproducibility. Here is kind of a hacky work around to make output from a LLM consistent (kind of). Also, a few observation regarding the same. Here I am following a MSFT article linked in the reference. Need to use the a GPT 4o model with version &lt;code&gt;2024-05-13&lt;/code&gt; for this. Also note here using AOAI API version &lt;code&gt;2024-10-21&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;setting-up-two-instances-of-llm-with-different-configs&#34;&gt;Setting up two instances of LLM with different configs&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;Deployment info
Name: gpt-4o
Model name: gpt-4o
Model version: 2024-05-13
Azure OAI API version: 2024-10-21
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-env&#34;&gt;AZURE_OPENAI_API_KEY=&amp;lt;AZURE_OPENAI_API_KEY&amp;gt;
AZURE_OPENAI_ENDPOINT=&amp;lt;AZURE_OPENAI_ENDPOINT&amp;gt;
AZURE_OPENAI_API_VERSION=&amp;quot;2024-10-21&amp;quot;
AZURE_OPENAI_GPT4O_MODEL_NAME=&amp;quot;gpt-4o&amp;quot;
AZURE_OPENAI_GPT4O_DEPLOYMENT_NAME=&amp;quot;gpt-4o&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from langchain_openai import AzureChatOpenAI
import pandas as pd
from dotenv import load_dotenv
import time
load_dotenv()
consistent_llm = AzureChatOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    azure_deployment=AZURE_OPENAI_GPT4O_DEPLOYMENT_NAME,
    api_version=AZURE_OPENAI_API_VERSION,
    temperature=0,
    seed=42,
    max_tokens=50
)
less_consistent_llm = AzureChatOpenAI(
    api_key = AZURE_OPENAI_API_KEY,
    azure_endpoint = AZURE_OPENAI_ENDPOINT,
    azure_deployment=AZURE_OPENAI_GPT4O_DEPLOYMENT_NAME,
    api_version=AZURE_OPENAI_API_VERSION,
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;generation-without-any-context&#34;&gt;Generation without any context&lt;/h3&gt;
&lt;p&gt;In this experiment generating 50 samples where the generation is not grounded on context. In way it is more free to choose the next word.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;consistent_arr_res = []
less_consistent_arr_res = []
messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;You are a helpful assistant.&amp;quot;},
    {
        &amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;,
        &amp;quot;content&amp;quot;: &amp;quot;Tell me a story about how the universe began? in 15 words&amp;quot;,
    },
]

for idx in range(50):
    print(f&amp;quot;Story Version {idx + 1}\n---&amp;quot;)
    consistent_res = consistent_llm.invoke(input=messages)
    less_consistent_res = less_consistent_llm.invoke(input=messages)
    less_consistent_arr_res.append(less_consistent_res.content)
    consistent_arr_res.append(consistent_res.content)
    print(&amp;quot;---\n&amp;quot;)
    del consistent_res
    del less_consistent_res

consistent_df = pd.DataFrame(consistent_arr_res, columns = [&#39;res&#39;])
less_consistent_df = pd.DataFrame(less_consistent_arr_res, columns = [&#39;res&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Observation in 50 generation with consistent LLM (with seed 42, max_token 50 and temperature 0) it has generated the below table.&lt;/p&gt;
&lt;h4 id=&#34;consistent-dataframe-1&#34;&gt;Consistent dataframe 1&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(consistent_df.value_counts().to_frame().to_markdown())
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;count&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;In a cosmic explosion, the universe expanded, stars formed, and life eventually emerged.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;19&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;ldquo;In a vast void, a singularity exploded, birthing stars, galaxies, and the universe&amp;rsquo;s endless wonders.&amp;rdquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;15&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;In a cosmic explosion, energy and matter formed stars, galaxies, and life, creating our universe.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;6&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;The universe began with a massive explosion, expanding rapidly, forming stars, galaxies, and cosmic wonders.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;3&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;The universe began with a massive explosion, expanding rapidly, forming stars, galaxies, and everything else.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;3&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;The universe began with a massive explosion, expanding rapidly, forming stars, galaxies, and life.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;3&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;ldquo;In a vast void, a singularity exploded, birthing stars, galaxies, and the universe&amp;rsquo;s wonders.&amp;rdquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;less-consistent-dataframe-1&#34;&gt;Less Consistent dataframe 1&lt;/h4&gt;
&lt;p&gt;Observation in 50 generation with inconsistent LLM it has generated the below table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(less_consistent_df.value_counts().to_frame()/head(5).to_markdown())
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;count&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A cosmic explosion birthed stars, planets, and galaxies, igniting the endless dance of creation.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;Stars ignited, galaxies whirled; from cosmic dawn, life sprung, evolving endlessly in infinite wonder.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;In the beginning, a Big Bang created stars, galaxies, and everything we know today.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;In the beginning, a cosmic explosion birthed stars, planets, and galaxies, igniting infinite possibilities.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;In the beginning, a massive explosion unleashed energy, forming stars, planets, and endless possibilities.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here showing just to 5 sample. But all 50 generation are unqiue.&lt;/p&gt;
&lt;h3 id=&#34;generation-with-context&#34;&gt;Generation with context&lt;/h3&gt;
&lt;p&gt;Now, we will ground generation using some context. Here is a short summary of short stories from wikipedia.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;text = &amp;quot;&amp;quot;&amp;quot;A short story is a piece of prose fiction. It can typically be read in a single sitting and focuses on a self-contained incident or series of linked incidents, with the intent of evoking a single effect or mood. The short story is one of the oldest types of literature and has existed in the form of legends, mythic tales, folk tales, fairy tales, tall tales, fables, and anecdotes in various ancient communities around the world. The modern short story developed in the early 19th century.[1]
Definition
The short story is a crafted form in its own right. Short stories make use of plot, resonance and other dynamic components as in a novel, but typically to a lesser degree. While the short story is largely distinct from the novel or novella/short novel, authors generally draw from a common pool of literary techniques.[citation needed] The short story is sometimes referred to as a genre.[2]
Determining what exactly defines a short story remains problematic.[3] A classic definition of a short story is that one should be able to read it in one sitting, a point most notably made in Edgar Allan Poe&#39;s essay &amp;quot;The Philosophy of Composition&amp;quot; (1846).[4] H. G. Wells described the purpose of the short story as &amp;quot;The jolly art, of making something very bright and moving; it may be horrible or pathetic or funny or profoundly illuminating, having only this essential, that it should take from fifteen to fifty minutes to read aloud.&amp;quot;[5] According to William Faulkner, a short story is character-driven and a writer&#39;s job is to &amp;quot;...trot along behind him with a paper and pencil trying to keep up long enough to put down what he says and does.&amp;quot;[6]
Some authors have argued that a short story must have a strict form. Somerset Maugham thought that the short story &amp;quot;must have a definite design, which includes a point of departure, a climax and a point of test; in other words, it must have a plot&amp;quot;.[5] Hugh Walpole had a similar view: &amp;quot;A story should be a story; a record of things happening full of incidents, swift movements, unexpected development, leading through suspense to a climax and a satisfying denouement.&amp;quot;[5]
This view of the short story as a finished product of art is however opposed by Anton Chekhov, who thought that a story should have neither a beginning nor an end. It should just be a &amp;quot;slice of life&amp;quot;, presented suggestively. In his stories, Chekhov does not round off the end but leaves it to the readers to draw their own conclusions.[5]
Sukumar Azhikode defined a short story as &amp;quot;a brief prose narrative with an intense episodic or anecdotal effect&amp;quot;.[3] Flannery O&#39;Connor emphasized the need to consider what is exactly meant by the descriptor short.[7] Short story writers may define their works as part of the artistic and personal expression of the form. They may also attempt to resist categorization by genre and fixed formation.[5]
William Boyd, a British author and short story writer, has said:
[a short story] seem[s] to answer something very deep in our nature as if, for the duration of its telling, something special has been created, some essence of our experience extrapolated, some temporary sense has been made of our common, turbulent journey towards the grave and oblivion.[8]
In the 1880s, the term &amp;quot;short story&amp;quot; acquired its modern meaning – having initially referred to children&#39;s tales.[9] During the early to mid-20th century, the short story underwent expansive experimentation which further hindered attempts to comprehensively provide a definition.[3] Longer stories that cannot be called novels are sometimes considered &amp;quot;novellas&amp;quot; or novelettes and, like short stories, may be collected into the more marketable form of &amp;quot;collections&amp;quot;. Around the world, the modern short story is comparable to lyrics, dramas, novels and essays – although examination of it as a major literary form remains diminished.[3][10]&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, asking LLMs to generate a summary using the given context.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;consistent_arr_res_summary = []
less_consistent_arr_res_summary = []
messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;You are a helpful assistant.&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: f&amp;quot;summarize this text in 15 words: {text}&amp;quot;},
]
for i in range(50):
    print(f&amp;quot;Story Version {i + 1}\n---&amp;quot;)
    consistent_res_summary = consistent_llm.invoke(input=messages)
    less_consistent_res_summary = less_consistent_llm.invoke(input=messages)
    less_consistent_arr_res_summary.append(less_consistent_res_summary.content)
    consistent_arr_res_summary.append(consistent_res_summary.content)
    print(&amp;quot;---\n&amp;quot;)
    del consistent_res_summary
    del less_consistent_res_summary
    time.sleep(1)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;consistent-dataframe-2&#34;&gt;Consistent dataframe 2&lt;/h4&gt;
&lt;p&gt;Observation in 50 generation with consistent LLM (with seed 42, max_token 50 and temperature 0) it has generated the below table. As you can see it is way more consistent. 46 time it has generated same output and 4 times the output is different but the main different in these two is of a single charecter.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(consistent_df_summary.value_counts().to_frame().to_markdown())
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;count&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A short story is a brief, self-contained prose fiction, read in one sitting, evoking a mood.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;46&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A short story is a brief, self-contained prose fiction, read in one sitting, evoking mood.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;4&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;less-consistent-dataframe-2&#34;&gt;Less Consistent dataframe 2&lt;/h4&gt;
&lt;p&gt;Observation in 50 generation with inconsistent LLM it has generated the below table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(less_consistent_df_summary.value_counts()head(5).to_frame().to_markdown())
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;count&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A short story is a brief piece of prose fiction read in a single sitting.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A short story is a concise prose narrative, focusing on a single effect or mood.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A short story is a brief, self-contained prose fiction focusing on a single effect or mood.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A short story is a brief, self-contained prose fiction focusing on a single incident or mood.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;(&amp;lsquo;A short story is a brief, self-contained prose fiction read in one sitting, evoking a single effect.&amp;rsquo;,)&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Again this is a sample of head 5. But as you can see that all the 50 generations are unique and different from one another.&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reproducible-output?tabs=pyton&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learn how to use reproducible output&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Short_story&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Short story&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Exponential Smoothing using Scikit-Learn wrapper &amp; statsmodels</title>
      <link>http://localhost:4321/post/exponential-smoothing-using-scikit-learn-wrapper-statsmodels/</link>
      <pubDate>Tue, 20 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/exponential-smoothing-using-scikit-learn-wrapper-statsmodels/</guid>
      <description>&lt;p&gt;As we discussed in previous post, in this series we will be working on different type of regression problem and will try to parse them as sklearn model objects. Here are we will be working with &lt;code&gt;ExponentialSmoothing&lt;/code&gt; from &lt;code&gt;statsmodels&lt;/code&gt; library. This is one of the most common time series model used in general. &lt;code&gt;statsmodels&lt;/code&gt; is heavily influence by R and its convention. If you take a deep dive into it&amp;rsquo;s functionality of or formula based approach in case of GLM, it is quite evident including the summary function.&lt;/p&gt;
&lt;p&gt;Here in this post our objective will be to take this &lt;code&gt;ExponentialSmoothing&lt;/code&gt; from &lt;code&gt;statsmodels&lt;/code&gt; and build a model class which looks like sklearn model and the method signatures are same in nature so there is less learning curve involved when there is a context switch or in this case a user is trying to build different models.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted
from sklearn.metrics import mean_absolute_percentage_error
import numpy as np
import pandas as pd
import inspect

class HWTimeSeriesSkLearnWrapper(BaseEstimator, RegressorMixin):
    def __init__(
        self,
        trend=None,
        damped_trend=False,
        seasonal=None,
        seasonal_periods=None,
        use_boxcox=False,
        optimized=True,
        remove_bias=False,
        initialization_method = None,
        model=ExponentialSmoothing,
    ):
        args, _, _, values = inspect.getargvalues(inspect.currentframe())
        values.pop(&amp;quot;self&amp;quot;)
        for arg, val in values.items():
            setattr(self, arg, val)

    def fit(self, X, y = None):
        if not X.empty:
            self.X = X
        self.model_ = self.model(
            self.X,
            trend=self.trend,
            seasonal=self.seasonal,
            seasonal_periods=self.seasonal_periods,
            damped_trend=self.damped_trend,
            use_boxcox=self.use_boxcox,
        )
        self.result_ = self.model_.fit(
            optimized=self.optimized, remove_bias=self.remove_bias
        )
        self.level = self.result_.level
        self.trend = self.result_.trend
        self.season = self.result_.season
        self.fitted_values = self.result_.fittedvalues
        return self

    def predict(self, X, y = None):
        check_is_fitted(self, &amp;quot;result_&amp;quot;)
        self.df = self.result_.forecast(X.index.size).to_frame()
        self.df.columns = [f&amp;quot;predicted_{name}&amp;quot; for name in X.columns]
        self.df.index.name = X.index.name
        return self.df

    def score(self, X, y):
        y_true = X.to_numpy().flatten()
        y_hat = self.predict(X).to_numpy().flatten()
        return mean_absolute_percentage_error(y_true= y_true, y_pred=y_hat)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see in the above block, I have come up with this structure which can take all the args of &lt;code&gt;__init__&lt;/code&gt; and &lt;code&gt;fit&lt;/code&gt; of &lt;code&gt;ExponentialSmoothing&lt;/code&gt; while initializing the wrapper class &lt;code&gt;HWTimeSeriesSkLearnWrapper&lt;/code&gt;. Note, these are not all the exhaustive set of parameter. You can take a look into the source code of the model class from &lt;code&gt;statsmodels&lt;/code&gt; and figure out what are the other parameters which can be helpful for your context.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;args, _, _, values = inspect.getargvalues(inspect.currentframe())
values.pop(&amp;quot;self&amp;quot;)
for arg, val in values.items():
    setattr(self, arg, val)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above chunk of the code will help to initialize arbitrary number of parameters for your model and in subsequent methods such as initialization or fit you can pass the parameter values from self. In the next block, I am downloading the data and creating a train test split. Note, in case of time series we need to remember two things,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Train test split can not be random&lt;/li&gt;
&lt;li&gt;There is no such concept of train and test data. Index is kind of your core feature along with meta features which can be derived from target.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The catch here is we need to create train and test in a way it can look like sklearn model but under the hood it should be able to use the same datasets for building times series model using statsmodels or any other library you may use.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_and_split_airline_data(test_size = 0.2, date_col = &amp;quot;month&amp;quot;, date_format = &amp;quot;%Y-%m&amp;quot;, date_freq = &amp;quot;MS&amp;quot;):
    df = pd.read_csv(&amp;quot;https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv&amp;quot;)
    df.columns = df.columns.str.lower()
    if date_col in df.columns:
        df[date_col] = pd.to_datetime(df[date_col], format = date_format)
        df = df.sort_values(date_col).set_index(date_col)
        df.index.freq = date_freq
    train_size = int(df.shape[0] * (1 - test_size))
    X_train = df.iloc[:train_size]
    X_test = df.iloc[train_size:]
    y_train = X_train.copy()
    y_test = X_test.copy()
    return X_train,X_test,y_train, y_test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, once we have the data we can use &lt;code&gt;fit&lt;/code&gt;, &lt;code&gt;predict&lt;/code&gt; and &lt;code&gt;score&lt;/code&gt; to calculate the required values.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X_train,X_test,y_train, y_test = get_and_split_airline_data()
model = HWTimeSeriesSkLearnWrapper(trend = &amp;quot;add&amp;quot;, damped_trend = True, seasonal = &amp;quot;add&amp;quot;, seasonal_periods = 12)
model.fit(X_train, y_train)
model.predict(X_test)
model.score(X_test, y_test)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>LASSO using Scikit-Learn wrapper &amp; CVXPY</title>
      <link>http://localhost:4321/post/lasso-using-scikit-learn-wrapper-and-cvxpy/</link>
      <pubDate>Sun, 18 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/lasso-using-scikit-learn-wrapper-and-cvxpy/</guid>
      <description>&lt;p&gt;Those who are working in ML space of sometime must be aware that there are multiple python libraries out there which support different algorithms/models. When you are trying to implement best model it is not possible to use just a single library or even a single language and compute infra. Also, note all the libraries are do not have the same method, signature and input and output. Hence if you are working on a library which is collection of multiple models from different library one good starting point can be to standardize you class, methods, signature and input and output. It helps us to avoid confusion, make things consistent and as result, when you are onboarding a new user, it takes them less time to learn things.&lt;/p&gt;
&lt;p&gt;At high level, it may sound easy to create common API structure for all the models but it is not. Many models take input in form of &lt;code&gt;np.ndarray&lt;/code&gt;, &lt;code&gt;pd.Series&lt;/code&gt;, &lt;code&gt;pd.DataFrame&lt;/code&gt;, &lt;code&gt;xarray&lt;/code&gt; objects and some libraries implement their own data object. To handle this project my current go to approach is to parse the inner working of a model in a sklearn wrapper with common methods, signature and input and output. In this example, we will see how we can do this using &lt;code&gt;cvxpy&lt;/code&gt; as optimizer and &lt;code&gt;sklearn&lt;/code&gt; wrapper to generate a &lt;code&gt;sklearn&lt;/code&gt; model object. Same thing can be done for &lt;code&gt;statsmodels&lt;/code&gt;, &lt;code&gt;pytorch&lt;/code&gt;, &lt;code&gt;tensorflow&lt;/code&gt; or any other custom logic.&lt;/p&gt;
&lt;p&gt;To start with we can create a &lt;code&gt;conda&lt;/code&gt; virtual env (assuming &lt;code&gt;conda&lt;/code&gt; is already installed. Otherwise install &lt;code&gt;conda&lt;/code&gt; python 3.8 first and then revisit this.). Run the following block to create a virtual env in &lt;code&gt;conda&lt;/code&gt; and install the required libraries,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n sklearn_wrapper python=3.8 -y
conda activate sklearn_wrapper
pip install scikit-learn cvxpy jupyter notebook pandas
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once this is done, we are good to start. Open a &lt;code&gt;jupyter notebook&lt;/code&gt; and execute the following lines in a cell,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted
import cvxpy as cp
import numpy as np
import pandas as pd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we are importing &lt;code&gt;BaseEstimator&lt;/code&gt; and &lt;code&gt;RegressorMixin&lt;/code&gt; which our custom model class will inherit from. &lt;code&gt;BaseEstimator&lt;/code&gt; will have default score method which can be over written and &lt;code&gt;RegressorMixin&lt;/code&gt; will have &lt;code&gt;get_params&lt;/code&gt; and &lt;code&gt;set_params&lt;/code&gt; methods which can be useful later while execution to change to value of a model parameter. Other than these we are importing &lt;code&gt;check_X_y&lt;/code&gt;, &lt;code&gt;check_array&lt;/code&gt; and &lt;code&gt;check_is_fitted&lt;/code&gt; from &lt;code&gt;sklearn&lt;/code&gt; which will be used to check if the X and y we are passing is of sklearn convention or not, the variable we are passing is of &lt;code&gt;array&lt;/code&gt; type of not and &lt;code&gt;check_is_fitted&lt;/code&gt; is to prevent running&lt;code&gt;predict&lt;/code&gt; before &lt;code&gt;fit&lt;/code&gt;. If we run predict, any model will expect &lt;code&gt;coeff&lt;/code&gt; or &lt;code&gt;weight&lt;/code&gt; to make any prediction, until we run &lt;code&gt;fit&lt;/code&gt; methods, these values will not be generated.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class CVXSkLearnWrapper(BaseEstimator, RegressorMixin):
    def __init__(self, alpha=1.0):
        self.alpha = alpha
        
    def _loss_fn(self, X, y, beta):
        return cp.norm2(X @ beta - y)**2

    def _regularizer(self, beta):
        return cp.norm1(beta)

    def _obj_fn(self, X, y, beta, lambd):
        return self._loss_fn(X, y, beta) + lambd * self._regularizer(beta)

    def _mse(self, X, Y, beta):
        return (1.0 / X.shape[0]) * self._loss_fn(X, Y, beta).value

    def fit(self, X, y):
        X, y = check_X_y(X, y)
        n = X.shape[1]
        beta = cp.Variable(n)
        lambd = cp.Parameter(nonneg=True)
        problem = cp.Problem(cp.Minimize(self._obj_fn(X, y, beta, lambd)))
        lambd.value = self.alpha
        problem.solve()
        self.coeff_ = beta.value
        self.intercept_ = 0.0
        return self
    
    def predict(self, X):
        check_is_fitted(self)
        X = check_array(X)
        return X @ self.coeff_
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the implementation LASSO using &lt;code&gt;CVXPY&lt;/code&gt; as &lt;code&gt;SKLearn&lt;/code&gt; model. Here in &lt;code&gt;__init__&lt;/code&gt; method we are taking &lt;code&gt;alpha&lt;/code&gt; as user input. Note, all the argument in &lt;code&gt;__init__&lt;/code&gt; method should have a default values. While storing them in &lt;code&gt;self&lt;/code&gt; the argument name of &lt;code&gt;__init__&lt;/code&gt; and reference in &lt;code&gt;self&lt;/code&gt; should be same. For example if we are using &lt;code&gt;__init__(self, alpha=1.0)&lt;/code&gt; then it must be store in &lt;code&gt;self&lt;/code&gt; as &lt;code&gt;self.alpha = alpha&lt;/code&gt;. This is a parameter which can be changed during execution using &lt;code&gt;get_params&lt;/code&gt; and &lt;code&gt;set_params&lt;/code&gt; method. To know about this optimization more check &lt;a href=&#34;https://www.cvxpy.org/examples/machine_learning/lasso_regression.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link. Note, here inside &lt;code&gt;fit&lt;/code&gt; method we have &lt;code&gt;X, y = check_X_y(X, y)&lt;/code&gt; this is not ensure that the &lt;code&gt;X, y&lt;/code&gt; variable we have passed to the &lt;code&gt;fit&lt;/code&gt; method is correct with respect to data type and share. Also, &lt;code&gt;fit&lt;/code&gt; method of &lt;code&gt;sklearn&lt;/code&gt; always return &lt;code&gt;self&lt;/code&gt;. In case of sklearn this is convention that any variable within in class with have a suffix &lt;code&gt;_&lt;/code&gt;. Here also we are saving, coefficients in &lt;code&gt;self.coeff_&lt;/code&gt;. Also, in &lt;code&gt;predict&lt;/code&gt; we are using &lt;code&gt;check_is_fitted(self)&lt;/code&gt; to check that the model has been fitted or not. I am using &lt;code&gt;check_array(X)&lt;/code&gt; in fit to ensure that the argument X is of type array.&lt;/p&gt;
&lt;p&gt;In the following block we are generating some synthetic data to fit the above model. Here &lt;code&gt;beta_star&lt;/code&gt; is the true parameter. &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; is the data on which we will fit the model and will try to estimate unknow &lt;code&gt;beta_star&lt;/code&gt; with derived &lt;code&gt;beta_hat&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def generate_data(m=100, n=20, sigma=5, density=0.2):
    &amp;quot;&amp;quot;&amp;quot;Generates data matrix X and observations Y.&amp;quot;&amp;quot;&amp;quot;
    np.random.seed(1)
    beta_star = np.random.randn(n)
    idxs = np.random.choice(range(n), int((1-density)*n), replace=False)
    for idx in idxs:
        beta_star[idx] = 0
    X = np.random.randn(m,n)
    Y = X.dot(beta_star) + np.random.normal(0, sigma, size=m)
    return X, Y, beta_star
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the following block we are generating the synthetic dataset, initializing lasso model with class &lt;code&gt;CVXSkLearnWrapper&lt;/code&gt; and &lt;code&gt;CVXSkLearnWrapper&lt;/code&gt;. After that we are executing &lt;code&gt;fit&lt;/code&gt; which will generate the coeffs &lt;code&gt;beta_hat&lt;/code&gt;, &lt;code&gt;predict&lt;/code&gt; will generate prediction &lt;code&gt;y_hat&lt;/code&gt; and &lt;code&gt;score&lt;/code&gt; will calculate R-sq between &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;y_hat&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X, y, _ = generate_data()
lasso = CVXSkLearnWrapper(alpha = 1.1)
model = lasso.fit(X, y)
model.predict(X)
model.score(X, y)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Here we are using &lt;code&gt;RegressorMixin&lt;/code&gt; but depending on the model type it any can &lt;code&gt;ClassifierMixin&lt;/code&gt;, &lt;code&gt;RegressorMixin&lt;/code&gt;, &lt;code&gt;ClusterMixin&lt;/code&gt; or &lt;code&gt;TransformerMixin&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;All the methods and signature of them should be same if you are implementing more than one model to build a library.&lt;/li&gt;
&lt;li&gt;If you have &lt;code&gt;_&lt;/code&gt; prefix before any method in the model class, it will not be exposed. It will be considered as internal method and can be accessed with the class.&lt;/li&gt;
&lt;li&gt;If we inherit from &lt;code&gt;BaseEstimator&lt;/code&gt; &amp;amp; &lt;code&gt;RegressorMixin&lt;/code&gt; there will be a default score function but it can be overwritten.&lt;/li&gt;
&lt;li&gt;To change score function in hyper-parameter tuning you can use &lt;code&gt;make_scorer&lt;/code&gt; and &lt;code&gt;greater_is_better&lt;/code&gt; in it.&lt;/li&gt;
&lt;li&gt;Dynamic parsing of &lt;code&gt;args&lt;/code&gt; is possible in &lt;code&gt;__init__&lt;/code&gt; method using &lt;code&gt;inspect&lt;/code&gt; module,&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import inspect

def __init__(self, arg1, arg2, arg3, ..., argN):
    args, _, _, values = inspect.getargvalues(inspect.currentframe())
    values.pop(&amp;quot;self&amp;quot;)
    for arg, val in values.items():
        setattr(self, arg, val)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;In this example, we are overwriting case &lt;code&gt;score&lt;/code&gt; function using &lt;code&gt;mean_absolute_percentage_error&lt;/code&gt;. Lets assume that for some reason we want to use &lt;code&gt;MAPE&lt;/code&gt; instate as default scoring method it can be useful. Other using &lt;code&gt;make_scorer&lt;/code&gt; can be used for any other custom score function or other sklearn score functions.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted
import cvxpy as cp
import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_percentage_error

class CVXSkLearnWrapper(BaseEstimator, RegressorMixin):
    def __init__(self, alpha=1.0):
        self.alpha = alpha
        
    def _loss_fn(self, X, y, beta):
        return cp.norm2(X @ beta - y)**2

    def _regularizer(self, beta):
        return cp.norm1(beta)

    def _obj_fn(self, X, y, beta, lambd):
        return self._loss_fn(X, y, beta) + lambd * self._regularizer(beta)

    def _mse(self, X, Y, beta):
        return (1.0 / X.shape[0]) * self._loss_fn(X, Y, beta).value

    def fit(self, X, y):
        X, y = check_X_y(X, y)
        n = X.shape[1]
        beta = cp.Variable(n)
        lambd = cp.Parameter(nonneg=True)
        problem = cp.Problem(cp.Minimize(self._obj_fn(X, y, beta, lambd)))
        lambd.value = self.alpha
        problem.solve()
        self.coeff_ = beta.value
        self.intercept_ = 0.0
        return self
    
    def predict(self, X):
        check_is_fitted(self)
        X = check_array(X)
        return X @ self.coeff_

    def score(self, X, y):
        y_hat = self.predict(X)
        return mean_absolute_percentage_error(y, y_hat)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;All the hyper-parameters (not derived from data) has to be initialized in &lt;code&gt;__init__&lt;/code&gt; method. Any model parameters (derived from data) must be initialized in &lt;code&gt;fit&lt;/code&gt;. Variable names in init should be always same as arg name and variables in fit should always have a suffix &lt;code&gt;_&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; are mandatory methods in &lt;code&gt;BaseEstimator&lt;/code&gt; class.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cvxpy.org/examples/machine_learning/lasso_regression.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LASSO regression using CVXPY&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielhnyk.cz/creating-your-own-estimator-scikit-learn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Creating your own estimator in scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://acme.byu.edu/00000179-d3f1-d7a6-a5fb-ffff6a2a0000/sklearn-1-pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to Scikit-Learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/32401493/how-to-create-customize-your-own-scorer-function-in-scikit-learn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How to create/customize your own scorer function in scikit-learn?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/model_evaluation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Avoid relative path import hell in python</title>
      <link>http://localhost:4321/post/avoid-relative-path-import-hell-in-python/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/avoid-relative-path-import-hell-in-python/</guid>
      <description>&lt;h1 id=&#34;__exploring-poetry-for-dependency-management-in-python__&#34;&gt;&lt;strong&gt;Exploring &lt;code&gt;poetry&lt;/code&gt; for dependency management in python&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;In general &lt;code&gt;pip&lt;/code&gt; &amp;amp; &lt;code&gt;venv&lt;/code&gt; is a good combination of tool when you don&amp;rsquo;t have to manage multiple dependencies for your project. But imaging that in a project you need to management multiple dependency files to deploy code into multiple envs. It is possible to do this with &lt;code&gt;pip&lt;/code&gt;, but in that case you need to manage multiple requirements files. To solve this project I have checked a few alternative like  &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;pipenv&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt; etc. According to my experience, poetry is the simplest and most efficient one. I was checking some of the useful tutorials about this and here I am just taking a note of some of the useful points regarding this tool.&lt;/p&gt;
&lt;h2 id=&#34;__some-useful-poetry-commands__&#34;&gt;&lt;strong&gt;Some useful &lt;code&gt;poetry&lt;/code&gt; commands&lt;/strong&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Download poetry in Ubuntu
curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -
source $HOME/.poetry/env # Add to PATH
poetry --version # Check version of poetry
poetry self update # Update version
poetry new project1 # Create a new project
cd project1
tree . 
poetry run pytest # Run pytest for the project
poetry add pandas # Add a package as dependency of a project
poetry remove pandas # Delete a project from the file
poetry add --dev pytest # Add a package as dev dependency in a poetry project
poetry add -D coverage[toml] pytest-cov # --dev &amp;amp; -D same
poetry install # Install all the dependencies for a project
poetry build # Build a python library using poetry
poetry publish # Publish library to PyPI
poetry export - requirements.txt --output requirements.txt # Generate requirements.txt
poetry use python3.8 # Use specific version of python in the project
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;__some-important-information__&#34;&gt;&lt;strong&gt;Some important information&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;__important-files__&#34;&gt;&lt;strong&gt;Important files&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pyproject.toml&lt;/code&gt; is the single file for all project related metadata.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;poetry.lock&lt;/code&gt; file is the granular metadata.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.pypirc&lt;/code&gt; will not work with poetry.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;config.toml&lt;/code&gt; &amp;amp; &lt;code&gt;auth.toml&lt;/code&gt; is used for setting up the artifact repository.&lt;/li&gt;
&lt;li&gt;export &lt;code&gt;POETRY_PYPI_TOKEN_PYPI&lt;/code&gt;, export &lt;code&gt;POETRY_HTTP_BAISC_PYPI_USERNAME&lt;/code&gt; and export &lt;code&gt;POETRY_HTTP_BAISC_PYPI_PASSWORD&lt;/code&gt; can be used for this.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;__publishing-library-as-artifact-to-artifact-store__&#34;&gt;&lt;strong&gt;Publishing library as artifact to artifact store&lt;/strong&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;# config.toml : ~/.config/pypoetry/config.toml
[repositories]
pypi = {url = &amp;quot;https://upload.pypi.org/legacy/&amp;quot;}
testpypi = {url = &amp;quot;https://test.pypi.org/legacy/&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;# auth.toml: ~/.config/pypoetry/auth.toml
[http-basic]
pypi = {username = &amp;quot;myuser&amp;quot;, password = &amp;quot;topsecret&amp;quot;}
testpypi = {username = &amp;quot;myuser&amp;quot;, password = &amp;quot;topsecret&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check GitHub issue related to this &lt;a href=&#34;https://github.com/python-poetry/poetry/issues/111&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;__reference__&#34;&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=G-OAVLBFxbw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyBites Python Poetry Training&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
