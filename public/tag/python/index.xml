<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python | Aritra Biswas</title>
    <link>https://academic-demo.netlify.app/tag/python/</link>
      <atom:link href="https://academic-demo.netlify.app/tag/python/index.xml" rel="self" type="application/rss+xml" />
    <description>python</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 18 Dec 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://academic-demo.netlify.app/media/icon_hu52c76baf5d1231d4145a3e91a90778a9_25217_512x512_fill_lanczos_center_3.png</url>
      <title>python</title>
      <link>https://academic-demo.netlify.app/tag/python/</link>
    </image>
    
    <item>
      <title>RecSys for B2B platform</title>
      <link>https://academic-demo.netlify.app/project/internal-project/</link>
      <pubDate>Sun, 18 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/project/internal-project/</guid>
      <description>&lt;p&gt;Currently, I am on &lt;code&gt;RecSys&lt;/code&gt; to generate product recommendations for ABI&amp;rsquo;s B2B platform &lt;code&gt;BEEs&lt;/code&gt;. Some of the challenges involved in the project include building &lt;code&gt;AutoML&lt;/code&gt; for best hyper-parameter selection, distributed model training. feature store integration, building a python library for curated ML models with default configs, deployment of models in cloud native compute and many more. Super excited to work in this work steam with an amazing team.&lt;/p&gt;
&lt;h3 id=&#34;__algorithm-related-challenges__&#34;&gt;&lt;strong&gt;Algorithm related challenges:&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cross validation:&lt;/strong&gt; How to perform cross validation for RecSys. How to link statistical metrics with business KPIs. Determining weighage between model goodness of fit and business KPIs. How to create a scoring function which can compare between different models during cross validation. Managing splitting strategy to ensure that models are comparable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model selection:&lt;/strong&gt; Single model or market-based model or hybrid model - combined of two or more models? Time/Sequence based models(&lt;code&gt;LSTM&lt;/code&gt;/&lt;code&gt;GRU&lt;/code&gt;)?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hyper parameter tuning:&lt;/strong&gt; What can be the preferable hyper-parameter tuning framework, which can support &lt;code&gt;GPU&lt;/code&gt; (Wide and Deep), Spark (&lt;code&gt;ALS&lt;/code&gt;) and CPU (&lt;code&gt;SAR&lt;/code&gt; etc.).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KPIs:&lt;/strong&gt; Evaluate existing KPIs such as &lt;code&gt;Map@K&lt;/code&gt;, &lt;code&gt;NDCG@K&lt;/code&gt; and improve if possible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hybrid model or mixture of model:&lt;/strong&gt; Also, what type of hybrid - sequential, parallel or weighted? As of now, two use case (conceptually)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Auto ML:&lt;/strong&gt; Example of AutoML for multi-country setup (including hybrid model, hyper-parameter tuning) with recommended tech stack.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model drift, data drift, retraining and model monitoring:&lt;/strong&gt; How to build a framework which can be integrated with the python library to detect model drift, data drift, retraining requirements and monitor generated results in online and offline models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Others:&lt;/strong&gt; backtesting, AB testing, linking online and offline evaluation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;__programming--infra-related-challenges__&#34;&gt;&lt;strong&gt;Programming &amp;amp; Infra related challenges:&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Code spaces:&lt;/strong&gt; How a developer can use code space for CPU based workflow for day-to-day development. Managing multiple envs base of &lt;code&gt;Spark/GPU/CPU&lt;/code&gt; dependencies using &lt;code&gt;devcontainer&lt;/code&gt;. Can the same image be used in &lt;code&gt;AML/ADB&lt;/code&gt;?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;AML&lt;/code&gt; + VS Code/Code Space Integration:&lt;/strong&gt; Attaching &lt;code&gt;AML&lt;/code&gt; compute to VS Code as terminal and &lt;code&gt;jupyter&lt;/code&gt; kernel. Run experiments in AML without leaving &lt;code&gt;VS Code/Code spaces&lt;/code&gt;. Triggering multiple concurrent jobs (not always same as distributed model training. Some of our models are classical models which we are running multiple times as embarrassingly parallel workload) in &lt;code&gt;AML&lt;/code&gt; from &lt;code&gt;VS Code&lt;/code&gt; which can scale in multiple nodes to run different models and return results in a fan out fan in pattern to a cloud storage. (One additional information here is we want to leverage all the cores within a node using &lt;code&gt;joblib&lt;/code&gt;, hence the auto scaling we are expecting is at node level for a given threshold) &lt;code&gt;mlflow&lt;/code&gt; integration with VS Code and AML.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;ADB&lt;/code&gt; + VS Code/Code Space Integration:&lt;/strong&gt; Run experiment in ADB without leaving VS Code/Code spaces.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Debugging:&lt;/strong&gt; Using VS Code visual debugger in a distributed workflow in &lt;code&gt;AML&lt;/code&gt; &amp;amp; &lt;code&gt;ADB&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; Monitoring aggregated logs from different nodes in &lt;code&gt;VS Code&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Testing:&lt;/strong&gt; How to run property based testing for ML models in distributed compute environments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Library:&lt;/strong&gt; Managing multiple dependencies such as &lt;code&gt;pyspark&lt;/code&gt;, &lt;code&gt;GPU&lt;/code&gt; and &lt;code&gt;CPU&lt;/code&gt; level system dependencies. Usage of &lt;code&gt;JIT&lt;/code&gt; within and across models taking execution infra into account. Making library infra agnostic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are interested in a similar work stream feel free to reach out to me.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Avoid relative path import hell in python</title>
      <link>https://academic-demo.netlify.app/post/avoid-relative-path-import-hell-in-python/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/post/avoid-relative-path-import-hell-in-python/</guid>
      <description>&lt;h1 id=&#34;__exploring-poetry-for-dependency-management-in-python__&#34;&gt;&lt;strong&gt;Exploring &lt;code&gt;poetry&lt;/code&gt; for dependency management in python&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;In general &lt;code&gt;pip&lt;/code&gt; &amp;amp; &lt;code&gt;venv&lt;/code&gt; is a good combination of tool when you don&amp;rsquo;t have to manage multiple dependencies for your project. But imaging that in a project you need to management multiple dependency files to deploy code into multiple envs. It is possible to do this with &lt;code&gt;pip&lt;/code&gt;, but in that case you need to manage multiple requirements files. To solve this project I have checked a few alternative like  &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;pipenv&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt; etc. According to my experience, poetry is the simplest and most efficient one. I was checking some of the useful tutorials about this and here I am just taking a note of some of the useful points regarding this tool.&lt;/p&gt;
&lt;h2 id=&#34;__some-useful-poetry-commands__&#34;&gt;&lt;strong&gt;Some useful &lt;code&gt;poetry&lt;/code&gt; commands&lt;/strong&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Download poetry in Ubuntu
curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -
source $HOME/.poetry/env # Add to PATH
poetry --version # Check version of poetry
poetry self update # Update version
poetry new project1 # Create a new project
cd project1
tree . 
poetry run pytest # Run pytest for the project
poetry add pandas # Add a package as dependency of a project
poetry remove pandas # Delete a project from the file
poetry add --dev pytest # Add a package as dev dependency in a poetry project
poetry add -D coverage[toml] pytest-cov # --dev &amp;amp; -D same
poetry install # Install all the dependencies for a project
poetry build # Build a python library using poetry
poetry publish # Publish library to PyPI
poetry export - requirements.txt --output requirements.txt # Generate requirements.txt
poetry use python3.8 # Use specific version of python in the project
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;__some-important-information__&#34;&gt;&lt;strong&gt;Some important information&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;__important-files__&#34;&gt;&lt;strong&gt;Important files&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pyproject.toml&lt;/code&gt; is the single file for all project related metadata.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;poetry.lock&lt;/code&gt; file is the granular metadata.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.pypirc&lt;/code&gt; will not work with poetry.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;config.toml&lt;/code&gt; &amp;amp; &lt;code&gt;auth.toml&lt;/code&gt; is used for setting up the artifact repository.&lt;/li&gt;
&lt;li&gt;export &lt;code&gt;POETRY_PYPI_TOKEN_PYPI&lt;/code&gt;, export &lt;code&gt;POETRY_HTTP_BAISC_PYPI_USERNAME&lt;/code&gt; and export &lt;code&gt;POETRY_HTTP_BAISC_PYPI_PASSWORD&lt;/code&gt; can be used for this.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;__publishing-library-as-artifact-to-artifact-store__&#34;&gt;&lt;strong&gt;Publishing library as artifact to artifact store&lt;/strong&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;# config.toml : ~/.config/pypoetry/config.toml
[repositories]
pypi = {url = &amp;quot;https://upload.pypi.org/legacy/&amp;quot;}
testpypi = {url = &amp;quot;https://test.pypi.org/legacy/&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;# auth.toml: ~/.config/pypoetry/auth.toml
[http-basic]
pypi = {username = &amp;quot;myuser&amp;quot;, password = &amp;quot;topsecret&amp;quot;}
testpypi = {username = &amp;quot;myuser&amp;quot;, password = &amp;quot;topsecret&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check GitHub issue related to this &lt;a href=&#34;https://github.com/python-poetry/poetry/issues/111&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;__reference__&#34;&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=G-OAVLBFxbw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyBites Python Poetry Training&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
